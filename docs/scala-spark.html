<!-- saved from url=(0050)http://10.4.11.97/~miyazawa/class/wiki/scala-spark -->
<!-- cleansed unused code block and adjusted some layout formatting by Kawaeee -->
<!-- For everyone, who want to get original version of the page, please check first commit! -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="ja" class="gr__10_4_11_97">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta http-equiv="content-style-type" content="text/css">
        <title>scala-spark - Miyazawa's Lecture Notes</title>
    </head>
    <body data-gr-c-s-loaded="true">
        <hr class="full_hr">
        <div id="body">
            <p>
            <h2 id="content_1_0">Scala language: A functional approach to data science (<a href="index.html" title="scala-course.18 (1d)">scala-course.18</a>)</p></h2>
            <h3 id="content_1_0"><a id="w9ad78f2">Apache Spark</a></h3>
            <h4 id="content_1_1"><a id="w9ad78f2">(optional) Review some Spark documentation</a></h4>
            <ul class="list2" style="padding-left:32px;margin-left:32px">
                <li>The official
                    <a href="https://spark.apache.org/docs/latest/" rel="nofollow">Spark Documentation</a>
                    is pretty good. Read through
                    the <a href="https://spark.apache.org/docs/latest/quick-start.html" rel="nofollow">Quick start</a> guide,
                    then quickly skim the <a href="http://spark.apache.org/docs/latest/rdd-programming-guide.html" rel="nofollow">Programming guide</a>,
                    then the<a href="https://spark.apache.org/docs/latestml-guide.html" rel="nofollow">ML guide</a>,
                    especially the section on Classification and regression.
                    Briefly familiarise yourself with
                    the <a href="https://spark.apache.org/docs/latest/api/scala/" rel="nofollow">API docs</a>.
                </li>
            </ul>
            <h4 id="content_1_2"><a id="i8ad8cc7">Logistic regression for the SpamBase dataset</a></h4>
            <ul class="list2" style="padding-left:32px;margin-left:32px">
                <li>Please get <a href="#error" title="MiyazawaClass:scala-course.18/tmp/spark.tar.gz" rel="nofollow">this tar file</a> and expand it in scala-course.18/root-dir-for-the-course/.</li>
            </ul>
            <ul class="list2" style="padding-left:32px;margin-left:32px">
                <li>This exercise will be concerned with analysis of the old SpamBase dataset.</li>
            </ul>
            <ul class="list3" style="padding-left:48px;margin-left:48px">
                <li>
                    After skimming the documentation:
                    <pre>ftp://ftp.ics.uci.edu/pub/machine-learning-databases/spambase/</pre>
                </li>
            </ul>
            <ul class="list3" style="padding-left:48px;margin-left:48px">
                <li>
                    Download the dataset:
                    <pre>ftp://ftp.ics.uci.edu/pub/machine-learning-databases/spambase/spambase.data</pre>
                    to your machine and move it somewhere sensible for subsequent analysis;
                    use <code>exercises/C8-Spark-exercise</code>.
                    It actually isn't very big, so don't worry about size/memory issues.
                </li>
            </ul>
            <ul class="list3" style="padding-left:48px;margin-left:48px">
                <li>The data is a simple CSV file, so can be parsed easily with Spark's built-in CSV parser. Complete a Spark application program (src/main/scala/LogRegBySpark/LogRegBySpark.scala) to read the data</li>
            </ul>
            <ul class="list3" style="padding-left:48px;margin-left:48px">
                <li>and fit a simple logistic regression model for the final column (Spam or not) given the other variables.
                    Use Lasso regression (L1 regression) to shrink out some of the variables. Choose your Lasso regularisation parameter by cross-validation.
                    Also, use standardization = false.  How many of the 57 predictor variables drop out of the regression in this case?
                </li>
            </ul>
            <h3 id="content_1_3"><a id="c4825758">TensorFlow Scala</a></h3>
            <ul class="list2" style="padding-left:32px;margin-left:32px">
                <li>
                    <a href="https://github.com/eaplatanios/tensorflow_scala" rel="nofollow">TensorFlow Scala</a> is a scala API for <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a>.
                    An example for object detection is found
                    <a href="https://brunk.io/deep-learning-in-scala-part-3-object-detection.html" rel="nofollow">here</a>
                    with <a href="https://github.com/sbrunk/scala-deeplearn-examples/blob/master/tensorflow/src/main/scala/io/brunk/examples/ObjectDetector.scala" rel="nofollow">source code</a>
                    <ul class="list3" style="padding-left:16px;margin-left:16px">
                        <li>Try to run this example by using sbt in scala-course.18/root-dir-for-the-course/C10-tensorflow-scala.</li>
                    </ul>
                </li>
            </ul>
            <h3 id="content_1_4"><a href="index.html" title="scala-course.18 (1d)" rel="nofollow">BACK: Main Page</a></h3>

        </div>
        <hr class="full_hr">
        Check out <a href="https://github.com/Kawaeee/scala_ds">GitHub</a> repository for more information!!
    </body>
</html>